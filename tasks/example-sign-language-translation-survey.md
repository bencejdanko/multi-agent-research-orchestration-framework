# Advances in Sign-Language Video-to-Text 

## Objective

Survey the current state-of-the-art in sign language video to text translations
for both visual and transformer models, with a focus on practical architectures that haveemerged in late 2025 / early 2026.

## Specific Questions

- What are the dominant models (Computer Vision, VLMs)?
- What are the prevelant data preparation approaches and techniques?

## arXiv
categories:
  - cs.CV        # Core: computer vision (video modeling)
  - cs.CL        # NLP / translation
  - cs.AI        # Multimodal / reasoning architectures
  - eess.IV      # Image & video processing (often relevant)
  
date_range:
  from: 2024-01-01
  to: 2026-12-31

keywords:
  - sign language translation
  - sign language recognition
  - sign language video-to-text
  - gloss-to-text
  - continuous sign language
  - multimodal transformer
  - video transformer
  - vision-language model
  - VLM
  - video-language alignment
  - temporal attention
  - spatiotemporal modeling

exclude_keywords:
  - speech recognition
  - audio-only
  - mixture of experts
  - LLM fine-tuning (unless multimodal)

max_papers: 50
citation_depth: 3
min_citations: 2
sort_by: submittedDate
